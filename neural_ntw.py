# -*- coding: utf-8 -*-
"""Neural-Ntw.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18A_jGbwX88MOpzgF3lOHRy8qRl3hds4d
"""



"""***Neural Network:***


Main use of tensorflow is for neural network

Tensorflow can also do classification and regression, Any ML model didn't have the feature that if accuracy is below certain level than can't update or increase features

Tensorflow support this updation bcz it works exactly like human brain

Brain:
information is stored in neurons

dentrites : through which input is given

data will move forward or gap b/t 2 neurons is filled by AXON

We have 2 and 3 but need output 7 then 2+3 =5 will be stored, one more neuron will be added containing 2 , add 2+5 and give the desired result

Cluster Computing : is used for this purpose


Pandas will load file on doing read_csv we can't change, In tensorflow, we have given a compiler type environment, it will only store and will not execute until we run it

***ANN: Artificaial neural network***

----->   we can decide No. of neurons 

dentrites = Input [No.of attributes or features]

Neurons = Node [Can be a PC or tpu or gpu of a system]

If there is no need to process input then simplest form of ANN i.e. single layered is enough.

Single layer means only input layer [we don't have to process the data]

Every hidden layer uses activation function to process the data received and then forward the output. 

No. of neuron should be kept equal to no. of  attributes/features

It is not must we can also keep 5 neuron if attributes are 10 but it is not a good practice

Power of hidden layers : traines data can be stored and used when required

TYpes of application fxn [there are many but we'll study these 4]

1) Threshold fxn 2) Sigmoid 3) Rectifier function 4) Hyperbolic Tangent


Developer team of google who made tensorflow is Brain Team

If there are more than 2 hidden layers in your ANN then we call it deep neural network

Cost function: to find error in actual output


God Father of deep learning -- Geoffrey Hinton  


6 months non stop to get hold of neural network

No. of neurons in hidden layer - no rule for it - but generally you can keep average of no. of neurons in input layer 

We can create our own activation function but there output should be in a form supported by the layer

Now if output which come is not as per wish:

And we don't want to change the data then we can apply multiplication with data such that value of data is not changed

m1,m2,m3=weight [the thig that we multiply]

y=m1x1+m2x2+m3x3

when multiplied by o -----------  it become o
when by 1------------------it is unchanged

Weight kon adjust karega -- har baar kisse multiply karna h -- is done by gradient decent
Gradient decent generate random numbers [brute force] and generate no. b/w 0 to 1

1) Normal gradient descent --- uses brute force
2) Stochastic gradient descent --- is a good method to be used

Gradiend descent is not a good method

If you'll not use gradient descent than even a supercomputer will take large amount of time to process it.

Loss function

Epoc -- 1 complete cycle from input layer to getting output 

We mention no. of epoc --- that is no. of times this cycle should go on or weight must be changed

What is batch size -- some % of data of each attribute is taken for processing that is data is taken in chunks and the % of data taken as chunk is random

neural network playground
"""